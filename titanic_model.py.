# Titanic – pipeline med Title/CabinLetter + GridSearch på GradientBoosting
import os, re
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.metrics import accuracy_score
from sklearn.ensemble import GradientBoostingClassifier

# Finn datafil
for p in ["data/train.csv", "train.csv"]:
    if os.path.exists(p):
        DATA_PATH = p
        break
else:
    raise FileNotFoundError("Fant ikke data/train.csv eller train.csv")

# 1) Les
df = pd.read_csv(DATA_PATH)

# 2) Feature engineering
def extract_title(name):
    m = re.search(r",\s*([^\.]+)\.", str(name))
    return m.group(1).strip() if m else "Unknown"

df["Title"] = df["Name"].apply(extract_title)

title_map = {
    "Mlle":"Miss","Ms":"Miss","Mme":"Mrs",
    "Lady":"Noble","Countess":"Noble","Sir":"Noble","Don":"Noble","Jonkheer":"Noble","Dona":"Noble",
    "Capt":"Officer","Col":"Officer","Major":"Officer","Dr":"Officer","Rev":"Clergy"
}
df["Title"] = df["Title"].replace(title_map)

df["CabinLetter"] = df["Cabin"].fillna("Unknown").astype(str).str[0]
df["CabinLetter"] = df["CabinLetter"].replace({"n":"Unknown","U":"Unknown"})

df["FamilySize"] = df["SibSp"] + df["Parch"] + 1
df["IsAlone"] = (df["FamilySize"] == 1).astype(int)

# Interaksjon som ofte hjelper
df["Pclass_Sex"] = df["Pclass"].astype(str) + "_" + df["Sex"].astype(str)

cols = ["Survived","Pclass","Sex","Age","SibSp","Parch","Fare","Embarked",
        "Title","CabinLetter","FamilySize","IsAlone","Pclass_Sex"]
df = df[cols].copy()

y = df["Survived"].astype(int)
X = df.drop(columns=["Survived"])

num_cols = ["Age","Fare","SibSp","Parch","FamilySize"]
cat_cols = ["Sex","Embarked","Title","CabinLetter","Pclass","Pclass_Sex","IsAlone"]

num_pipe = Pipeline([("imp", SimpleImputer(strategy="median"))])
cat_pipe = Pipeline([
    ("imp", SimpleImputer(strategy="most_frequent")),
    ("oh", OneHotEncoder(handle_unknown="ignore"))
])

pre = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols),
])

gb = GradientBoostingClassifier(random_state=42)

pipe = Pipeline([
    ("pre", pre),
    ("gb", gb)
])

# Tuning – liten, rask grid
param_grid = {
    "gb__n_estimators": [150, 250, 350],
    "gb__learning_rate": [0.05, 0.08, 0.1],
    "gb__max_depth": [2, 3],
    "gb__min_samples_split": [2, 4],
    "gb__min_samples_leaf": [1, 2],
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
gs = GridSearchCV(pipe, param_grid, cv=cv, scoring="accuracy", n_jobs=-1)
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

gs.fit(X_tr, y_tr)
best_pipe = gs.best_estimator_

pred = best_pipe.predict(X_te)
acc = accuracy_score(y_te, pred)

print(f"Hold-out accuracy: {acc:.3f}")
print("Best params:", gs.best_params_)
